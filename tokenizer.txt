# This is not meant to run. It's pseudocode.

# Autonaton evaluation.
def getToken(ctx, auts):
  # Initialize
  for aut in auts:
    aut.init()

  # Transition all automata until they're either
  # all dead or the input file runs out.
  # Afterwards, find which automaton had the longest match.
  last_accept = [0 for _ in auts]
  current_state = [0 for _ in auts]
  for c, iidx in enumerate(input_str):
    all_dead = True
    for aut, aidx in enumerate(auts):
      # No need to step what's already dead.
      if !aut.dead:
        all_dead = False
      else:
        continue

      # Step automaton state, note if it accepted and where.
      # Keep track of the last time each automata
      # accepted before it died.
      current_state[aidx] = aut.transition(c)
      if aut.accepting:
        last_accept[] = iidx + 1;

    if all_dead:
      break

  # Figure out what token we just consumed
  # Resolve multiple accepts with the first
  # to appear in the tokenizer file.
  num_chars, tokid = find_accept(last_accept)
  if not tokid:
    return None

  tokstr = input_str[ctx.pos:ctx.pos + num_chars]
  return Token(tokid, tokstr)
